{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DogBreedClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOo2PEj8wzKBG9dXslKba/G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeardedBaldo/Dog_Breed_Classifier/blob/main/DogBreedClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_GKct3RQfU6"
      },
      "source": [
        "import requests\n",
        "import tarfile\n",
        "import os\n",
        "from PIL import Image\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj9LCVbNTPLI"
      },
      "source": [
        "## download stanford dog dataset\n",
        "url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\"\n",
        "r = requests.get(url, allow_redirects = True) \n",
        "open(\"images.tar\", \"wb\").write(r.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4ErQ7MyTjXr"
      },
      "source": [
        "### untaring the dataset\n",
        "tar = tarfile.open(\"images.tar\")\n",
        "tar.extractall(\"./\")\n",
        "tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFdLiRdJuEWw"
      },
      "source": [
        "### check for gpus and assign to device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s4z3Lb7qaNP"
      },
      "source": [
        "### image loader function and transform object\n",
        "\n",
        "imageSize = (128, 128) if torch.cuda.is_available() else (128, 128)\n",
        "\n",
        "loader = transforms.Compose([transforms.Resize(imageSize), \n",
        "                             transforms.ToTensor(),\n",
        "                             transforms.Normalize((0.485, 0.456, 0.406),\n",
        "                                                  (0.229, 0.224, 0.225))\n",
        "                             ])\n",
        "\n",
        "def imageLoader(imagePath):\n",
        "  image = Image.open(imagePath)\n",
        "  image = loader(image).unsqueeze(0)\n",
        "  return image.to(device, torch.float)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0P4gWPAtK8c"
      },
      "source": [
        "### test image load\n",
        "samplePath = './Images/n02085620-Chihuahua/n02085620_10074.jpg'\n",
        "\n",
        "sampleImage = imageLoader(samplePath)\n",
        "\n",
        "print(type(sampleImage))\n",
        "print(sampleImage.size())\n",
        "\n",
        "newSize = (128, 128)\n",
        "sampleTransform = transforms.Resize(newSize)\n",
        "resizedImage = sampleTransform(sampleImage)\n",
        "print(type(resizedImage))\n",
        "print(resizedImage.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD8WlN2r-VAM"
      },
      "source": [
        "### variable initialization\n",
        "dataDir = \"./Images\"\n",
        "testSplit = 0.2\n",
        "valSplit = 0.2\n",
        "epochs = 10\n",
        "featureExtract = True\n",
        "modelName = \"vgg19\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HfNfNXZUklD"
      },
      "source": [
        "### load data and split into train and test\n",
        "\n",
        "## delete 2933 from Shetland sheeps since its a png\n",
        "\n",
        "dataDict = {\"train\": {\n",
        "    \"images\": [],\n",
        "    \"labels\": []\n",
        "}, \"validation\": {\n",
        "    \"images\": [],\n",
        "    \"labels\": []    \n",
        "}}\n",
        "trainLabels = []\n",
        "trainImages = []\n",
        "mapping = []\n",
        "testLabels = []\n",
        "testImages = []\n",
        "\n",
        "sampleList = ['./Images/n02108000-EntleBucher', './Images/n02111889-Samoyed']\n",
        "\n",
        "for i, (root, dirs, files) in enumerate(os.walk(dataDir)):\n",
        "  if root != dataDir:# and root in sampleList:    ### add root in sampleList condition only for testing\n",
        "    name = root.split(\"/\")[-1].split(\"-\")[-1]\n",
        "    mapping.append(name)\n",
        "    print(root)\n",
        "    print(name, \" : \", i)\n",
        "    nFiles = len(files)\n",
        "    for j, f in enumerate(files):\n",
        "      filePath = os.path.join(root, f)\n",
        "      image = imageLoader(filePath)\n",
        "      if j < (nFiles * (1 - testSplit)):\n",
        "        trainImages.append(image)\n",
        "        trainLabels.append(i-1)\n",
        "      else:\n",
        "        testImages.append(image)\n",
        "        testLabels.append(i-1)\n",
        "      del image\n",
        "\n",
        "trainData = {}\n",
        "trainData[\"trainImages\"] = trainImages\n",
        "trainData[\"trainLabels\"] = trainLabels\n",
        "nClasses = len(mapping)\n",
        "    \n",
        "print(trainData.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHQjpP8-izmY"
      },
      "source": [
        "### train validation split \n",
        "trainImages, validationImages, trainLabels, validationLabels = train_test_split(trainImages, trainLabels, test_size = valSplit)\n",
        "dataDict[\"train\"][\"images\"] = trainImages\n",
        "dataDict[\"validation\"][\"images\"] = validationImages\n",
        "dataDict[\"train\"][\"labels\"] = trainLabels\n",
        "dataDict[\"validation\"][\"labels\"] = validationLabels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9XqHFQN_ZK0"
      },
      "source": [
        "### set requires_grad for model parameters\n",
        "\n",
        "def setParameterRequiresGrad(model, featureExract):\n",
        "  if featureExtract:\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8XyMzsLcaHZ"
      },
      "source": [
        "### model initialization\n",
        "\n",
        "def initializeModel(modelName, nClasses, featureExtract, \n",
        "                    use_pretrained = True):\n",
        "  modelFt = None\n",
        "  inputSize = 0\n",
        "\n",
        "  if modelName == \"resnet\":\n",
        "    modelFt = models.resnet50(pretrained = use_pretrained)\n",
        "    setParameterRequiresGrad(modelFt, featureExtract)\n",
        "    nFeatures = modelFt.fc.in_features\n",
        "    modelFt.fc = nn.Linear(nFeatures, nClasses)\n",
        "    inputSize = (224, 224)\n",
        "\n",
        "  elif modelName == \"vgg11\":\n",
        "    modelFt = models.vgg11_bn(pretrained=use_pretrained)\n",
        "    setParameterRequiresGrad(modelFt, featureExtract)\n",
        "    nFeatures = modelFt.classifier[6].in_features\n",
        "    modelFt.classifier[6] = nn.Linear(nFeatures, nClasses)\n",
        "    inputSize = (224, 224)\n",
        "\n",
        "  elif modelName == \"vgg19\":\n",
        "    modelFt = models.vgg19_bn(pretrained=use_pretrained)\n",
        "    setParameterRequiresGrad(modelFt, featureExtract)\n",
        "    nFeatures = modelFt.classifier[6].in_features\n",
        "    modelFt.classifier[6] = nn.Linear(nFeatures, nClasses)\n",
        "    inputSize = (224, 224)\n",
        "\n",
        "  elif modelName == \"inception\":\n",
        "    modelFt = models.inception_v3(pretrained = use_pretrained)\n",
        "    setParameterRequiresGrad(modelFt, featureExtract)\n",
        "    nFeatures = modelFt.AuxLogits.fc.in_features\n",
        "    modelFt.AuxLogits.fc = nn.Linear(nFeatures, nClasses)\n",
        "    nFeatures = modelFt.fc.in_features\n",
        "    modelFt.fc = nn.Linear(nFeatures, nClasses)\n",
        "    inputSize = (299, 299)\n",
        "\n",
        "  else:\n",
        "    print(\"Invalid model name, exiting...\")\n",
        "    exit()\n",
        "\n",
        "  return modelFt, inputSize \n",
        "\n",
        "modelFt, inputSize = initializeModel(modelName, nClasses,\n",
        "                                     featureExtract)\n",
        "print(modelFt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIcA9SuFeoro"
      },
      "source": [
        "### model GPU initialization, optimizer initialization\n",
        "\n",
        "## send model to GPU\n",
        "modelFt = modelFt.to(device)\n",
        "\n",
        "\n",
        "## print parameters to learn\n",
        "print(\"Parameters to learn\")\n",
        "if featureExtract:\n",
        "  paramsUpdate = []\n",
        "  for name, param in modelFt.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "      paramsUpdate.append(param)\n",
        "      print(\"\\t\", name)\n",
        "else:\n",
        "  paramsUpdate = modelFt.parameters()\n",
        "  for name, param in modelFt.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "      print(\"\\t\", name)\n",
        "\n",
        "\n",
        "## initialize optimizer\n",
        "optimizerFt = optim.Adam(paramsUpdate, lr = 0.001) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj_8-zkNlF0g"
      },
      "source": [
        "### model training function\n",
        "\n",
        "def trainModel(model, dataDict, criterion, optimizer, \n",
        "               inputSize, nEpochs = 10, isInception = False):\n",
        "  start = time.time()\n",
        "\n",
        "  trainAccHistory = []\n",
        "  valAccHistory = []\n",
        "\n",
        "  bestModelWts = copy.deepcopy(model.state_dict())\n",
        "  bestAcc = 0\n",
        "\n",
        "  modelTransform = transforms.Resize(inputSize) \n",
        "\n",
        "  for epoch in range(nEpochs):\n",
        "    print(f'Epoch {epoch}/{nEpochs - 1}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    for phase in dataDict.keys():\n",
        "      if phase == \"train\":\n",
        "        model.train()\n",
        "      else:\n",
        "        model.eval()\n",
        "\n",
        "      runningLoss = 0.0\n",
        "      runningCorrects = 0\n",
        "\n",
        "      inputs = dataDict[phase][\"images\"]\n",
        "      labels = dataDict[phase][\"labels\"]\n",
        "\n",
        "      for i, input in enumerate(inputs):\n",
        "        input = modelTransform(input).to(device)\n",
        "        label = []\n",
        "        label.append(labels[i])\n",
        "        label = torch.tensor(np.array(label)).to(device)\n",
        "        \n",
        "        ##zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(phase == \"train\"):\n",
        "\n",
        "          if isInception:\n",
        "            output, auxOutput = model(input)\n",
        "            mainLoss = criterion(output, label)\n",
        "            auxLoss = criterion(auxOutput, label)\n",
        "            loss = mainLoss + 0.4 * auxLoss\n",
        "          else:\n",
        "            output = model(input)\n",
        "            loss = criterion(output, label)\n",
        "\n",
        "          _, prediction = torch.max(output, 1)\n",
        "\n",
        "          if phase == \"train\":\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        runningLoss += loss.item() * input.size(0)\n",
        "        runningCorrects += torch.sum(prediction == label)\n",
        "\n",
        "      epochLoss = runningLoss / (len(inputs))\n",
        "      epochAcc = runningCorrects.double() / (len(inputs))\n",
        "      \n",
        "      print(\"{} loss: {:4f}, {} accuracy: {:4f}\".format(phase,\n",
        "                                                        epochLoss,\n",
        "                                                        phase,\n",
        "                                                        epochAcc))\n",
        "      if phase == \"train\":\n",
        "        trainAccHistory.append(epochAcc)\n",
        "      else:\n",
        "        valAccHistory.append(epochAcc)\n",
        "\n",
        "      if phase == \"validation\" and epochAcc > bestAcc:\n",
        "        bestAcc = epochAcc\n",
        "        bestModelWts = copy.deepcopy(model.state_dict())\n",
        "      \n",
        "\n",
        "      \n",
        "\n",
        "  timeTaken = time.time() - start\n",
        "  print(\"training complete in {:.0f}m {:.0f}s\".format(timeTaken // 60,\n",
        "                                         timeTaken % 60))\n",
        "  \n",
        "  print(\"Best validation accuracy: {:4f}\".format(bestAcc))\n",
        "\n",
        "  model.load_state_dict(bestModelWts)\n",
        "\n",
        "  return model, trainAccHistory, valAccHistory\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z75oym7A74n"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "modelFt, trainhist, valHist = trainModel(modelFt, dataDict, criterion,\n",
        "                           optimizerFt, inputSize,\n",
        "                           nEpochs = epochs,\n",
        "                           isInception = (modelName == \"inception\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byfd6O6JvpeE"
      },
      "source": [
        "###\n",
        "tHist = [h.cpu().numpy() for h in trainhist]\n",
        "vHist = [h.cpu().numpy() for h in valHist]\n",
        "\n",
        "plt.xlabel(\"training epochs\")\n",
        "plt.ylabel(\"training accuracy\")\n",
        "plt.plot(range(1, epochs+1), tHist)\n",
        "plt.plot(range(1, epochs+1), vHist)\n",
        "plt.ylim((0, 1.))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tCfmE94nWW7"
      },
      "source": [
        "### model evaluation\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "modelTransform = transforms.Resize(inputSize)\n",
        "\n",
        "with torch.no_grad():\n",
        "  modelFt.eval()\n",
        "  inputs = testImages\n",
        "  labels = testLabels\n",
        "  for i, input in enumerate(inputs):\n",
        "      input = modelTransform(input).to(device)\n",
        "      label = []\n",
        "      label.append(labels[i])\n",
        "      label = torch.tensor(np.array(label)).to(device)\n",
        "      output = modelFt(input)\n",
        "      _, predicted = torch.max(output, 1)\n",
        "      #print(\"Label:\", int(label[0]), \", Predicted:\", int(predicted[0]))\n",
        "      total += label.size(0)\n",
        "      correct += (predicted==label).sum().item()\n",
        "\n",
        "print(\"Testing accuracy: \", (correct/total) * 100)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwzKcoRGzjEp"
      },
      "source": [
        "### prediction \n",
        "predictPath = \"./Images/n02086240-Shih-Tzu/n02086240_1011.jpg\"\n",
        "\n",
        "def predictBreed(predictPath, model, mapping):\n",
        "  input = imageLoader(predictPath)\n",
        "  with torch.no_grad():\n",
        "    input = modelTransform(input).to(device)\n",
        "    output = model(input)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    predictedLabel = int(predicted[0])\n",
        "    predictedBreed = mapping[predictedLabel]\n",
        "\n",
        "  return predictedBreed\n",
        "\n",
        "predictBreed = predictBreed(predictPath, modelFt, mapping)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_7kh-MAkY3y",
        "outputId": "b7a1c925-adb6-4331-e769-cec010acb08d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(predictBreed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tzu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTmqfOTxkB7Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}